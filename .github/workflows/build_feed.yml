name: Build filtered CSV feed

on:
  schedule:
    - cron: "*/15 * * * *"   # ogni 15 minuti
    - cron: "5 0 * * *"      # daily baseline reset (UTC)
  workflow_dispatch:

concurrency:
  group: feed-filter
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Download source CSV
        run: |
          set -e
          echo "Downloading source..."
          curl -L --retry 5 --retry-delay 5 --connect-timeout 30 --max-time 3600 \
            -w "\nHTTP_CODE=%{http_code}\nFINAL_URL=%{url_effective}\n" \
            "${{ secrets.SOURCE_CSV_URL }}" -o source.csv

          echo "Downloaded file:"
          ls -lh source.csv
          echo "Header preview:"
          head -n 2 source.csv | cat

      - name: Filter CSV
        run: |
          set -e
          python filter_feed.py

          echo "Filtered file:"
          ls -lh filtered.csv
          echo "Filtered header preview:"
          head -n 2 filtered.csv | cat

      - name: Install Google API deps
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install google-api-python-client google-auth

      - name: Write service account JSON to file
        env:
          GDRIVE_SA_JSON: ${{ secrets.GDRIVE_SA_JSON }}
        run: |
          set -e
          if [ -z "$GDRIVE_SA_JSON" ]; then
            echo "GDRIVE_SA_JSON secret is empty or missing"
            exit 1
          fi

          echo "$GDRIVE_SA_JSON" > sa.json

          python - << 'PY'
          import json
          with open("sa.json","r",encoding="utf-8") as f:
              obj = json.load(f)
          print("SA client_email:", obj.get("client_email"))
          PY

      - name: Upload filtered.csv to Google Drive (overwrite by fileId)
        env:
          GDRIVE_FILE_ID: ${{ secrets.GDRIVE_FILE_ID }}
        run: |
          set -e
          python - << 'PY'
          import os
          from google.oauth2 import service_account
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload

          file_id = os.environ.get("GDRIVE_FILE_ID","").strip()
          if not file_id:
              raise RuntimeError("GDRIVE_FILE_ID is empty or missing")

          creds = service_account.Credentials.from_service_account_file(
              "sa.json",
              scopes=["https://www.googleapis.com/auth/drive"]
          )
          service = build("drive", "v3", credentials=creds)

          media = MediaFileUpload("filtered.csv", mimetype="text/csv", resumable=True)
          updated = service.files().update(fileId=file_id, media_body=media).execute()

          print("Updated Drive file:", updated.get("id"))
          PY

      # ==============================
      # BASELINE: daily reset (UTC)
      # ==============================
      - name: Build baseline_skus.txt (daily)
        if: github.event_name == 'schedule' && github.event.schedule == '5 0 * * *'
        run: |
          set -e
          python - << 'PY'
          import csv

          # Estrae SKU unici dal filtered.csv e salva baseline_skus.txt (1 sku per riga)
          with open("filtered.csv", "r", encoding="utf-8", newline="") as f:
            reader = csv.reader(f)
            header = next(reader, [])
            header_l = [h.strip().lower() for h in header]
            if not header_l:
              raise RuntimeError("filtered.csv header missing")

            # tollerante: sku potrebbe essere 'sku' o simili
            def find_col(names):
              for n in names:
                if n in header_l:
                  return header_l.index(n)
              return -1

            sku_i = find_col(["sku","seller_sku","item_sku"])
            if sku_i < 0:
              raise RuntimeError("SKU column not found in filtered.csv")

            seen = set()
            for row in reader:
              if not row: 
                continue
              sku = (row[sku_i] if sku_i < len(row) else "").strip()
              if sku:
                seen.add(sku)

          with open("baseline_skus.txt","w",encoding="utf-8",newline="\n") as out:
            for sku in sorted(seen):
              out.write(sku + "\n")

          print("Baseline SKUs:", len(seen))
          PY

      - name: Upload baseline_skus.txt to Google Drive (overwrite by fileId)
        if: github.event_name == 'schedule' && github.event.schedule == '5 0 * * *'
        env:
          BASELINE_FILE_ID: ${{ secrets.BASELINE_FILE_ID }}
        run: |
          set -e
          python - << 'PY'
          import os
          from google.oauth2 import service_account
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload

          file_id = os.environ.get("BASELINE_FILE_ID","").strip()
          if not file_id:
              raise RuntimeError("BASELINE_FILE_ID is empty or missing")

          creds = service_account.Credentials.from_service_account_file(
              "sa.json",
              scopes=["https://www.googleapis.com/auth/drive"]
          )
          service = build("drive", "v3", credentials=creds)

          media = MediaFileUpload("baseline_skus.txt", mimetype="text/plain", resumable=True)
          updated = service.files().update(fileId=file_id, media_body=media).execute()

          print("Updated baseline file:", updated.get("id"))
          PY

      # ==============================
      # DIFF: every 15 min (and manual)
      # ==============================
      - name: Download baseline_skus.txt from Google Drive
        if: github.event_name != 'schedule' || github.event.schedule != '5 0 * * *'
        env:
          BASELINE_FILE_ID: ${{ secrets.BASELINE_FILE_ID }}
        run: |
          set -e
          python - << 'PY'
          import os
          from google.oauth2 import service_account
          from googleapiclient.discovery import build

          file_id = os.environ.get("BASELINE_FILE_ID","").strip()
          if not file_id:
              raise RuntimeError("BASELINE_FILE_ID is empty or missing")

          creds = service_account.Credentials.from_service_account_file(
              "sa.json",
              scopes=["https://www.googleapis.com/auth/drive"]
          )
          service = build("drive", "v3", credentials=creds)

          data = service.files().get_media(fileId=file_id).execute()
          # data Ã¨ bytes
          with open("baseline_skus.txt","wb") as f:
            f.write(data)

          print("Downloaded baseline_skus.txt bytes:", len(data))
          PY

      - name: Build new_skus_0930.csv (diff vs baseline)
        if: github.event_name != 'schedule' || github.event.schedule != '5 0 * * *'
        run: |
          set -e
          python - << 'PY'
          import csv

          # 1) carica baseline
          baseline = set()
          with open("baseline_skus.txt","r",encoding="utf-8",errors="ignore") as f:
            for line in f:
              s = line.strip()
              if s:
                baseline.add(s)

          # 2) diff sul filtered.csv e scrivi new_skus_0930.csv
          with open("filtered.csv","r",encoding="utf-8",newline="") as fin:
            reader = csv.reader(fin)
            header = next(reader, [])
            header_l = [h.strip().lower() for h in header]

            def find_col(names):
              for n in names:
                if n in header_l:
                  return header_l.index(n)
              return -1

            sku_i = find_col(["sku","seller_sku","item_sku"])
            supplier_i = find_col(["supplier_code","supplier","supplierid","supplier_id"])
            name_i = find_col(["name","title","product_name"])
            qty_i = find_col(["qty","quantity","quantita","stock"])
            cat_i = find_col(["category","cat1","categoria"])
            cost_i = find_col(["cost","price","base_price","prezzo","net_price"])

            if sku_i < 0:
              raise RuntimeError("SKU column not found in filtered.csv")

            out_header = ["sku","supplier_code","name","qty","category","cost"]

            rows_out = 0
            with open("new_skus_0930.csv","w",encoding="utf-8",newline="") as fout:
              w = csv.writer(fout)
              w.writerow(out_header)

              for row in reader:
                if not row:
                  continue
                sku = (row[sku_i] if sku_i < len(row) else "").strip()
                if not sku:
                  continue
                if sku in baseline:
                  continue

                supplier = (row[supplier_i] if supplier_i >= 0 and supplier_i < len(row) else "").strip()
                name = (row[name_i] if name_i >= 0 and name_i < len(row) else "").strip()
                qty = (row[qty_i] if qty_i >= 0 and qty_i < len(row) else "").strip()
                cat = (row[cat_i] if cat_i >= 0 and cat_i < len(row) else "").strip()
                cost = (row[cost_i] if cost_i >= 0 and cost_i < len(row) else "").strip()

                w.writerow([sku, supplier, name, qty, cat, cost])
                rows_out += 1

          print("Baseline size:", len(baseline))
          print("New SKUs rows:", rows_out)
          PY

      - name: Upload new_skus_0930.csv to Google Drive (overwrite by fileId)
        if: github.event_name != 'schedule' || github.event.schedule != '5 0 * * *'
        env:
          NEWSKUS_FILE_ID: ${{ secrets.NEWSKUS_FILE_ID }}
        run: |
          set -e
          python - << 'PY'
          import os
          from google.oauth2 import service_account
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload

          file_id = os.environ.get("NEWSKUS_FILE_ID","").strip()
          if not file_id:
              raise RuntimeError("NEWSKUS_FILE_ID is empty or missing")

          creds = service_account.Credentials.from_service_account_file(
              "sa.json",
              scopes=["https://www.googleapis.com/auth/drive"]
          )
          service = build("drive", "v3", credentials=creds)

          media = MediaFileUpload("new_skus_0930.csv", mimetype="text/csv", resumable=True)
          updated = service.files().update(fileId=file_id, media_body=media).execute()

          print("Updated new_skus file:", updated.get("id"))
          PY

      - name: Upload artifact (debug)
        uses: actions/upload-artifact@v4
        with:
          name: filtered-feed
          path: filtered.csv
          if-no-files-found: error
          retention-days: 3

      - name: Upload artifact (debug new_skus)
        uses: actions/upload-artifact@v4
        with:
          name: new-skus
          path: new_skus_0930.csv
          if-no-files-found: error
          retention-days: 3

      - name: Upload artifact (debug baseline)
        uses: actions/upload-artifact@v4
        with:
          name: baseline-skus
          path: baseline_skus.txt
          if-no-files-found: warn
          retention-days: 3
